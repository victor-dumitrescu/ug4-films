\documentclass[bsc,frontabs,singlespacing,parskip]{infthesis} % add [twoside]
\usepackage{filecontents}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{multirow}

\usepackage{tikz}
\usetikzlibrary{bayesnet}
\usepackage{dirtree}
\usepackage{array}
\usepackage{xcolor, colortbl}
\usepackage{hhline}
\usepackage{chngpage}

\begin{document}
\long\def\/*#1*/{}

\title{Representing Films as Character Graphs}

\author{Victor Dumitrescu}

\course{Artificial Intelligence and Computer Science}
\project{4th Year Project Report}

\date{\today}

\abstract{
This project sets out to explore a representation of films in terms of their characters, bringing together different kinds of textual information, such as screenplays and plot summaries. The work described in this report builds upon the existing literature in computational linguistics concerned with studying characters in films and other works of fiction. The character graphs presented here model two main aspects of film characters: their personalities and their role in the social network of the narrative. We try to show that by using both kinds of features to represent films, we can derive some insight into deeper aspects of the narratives.
}

\maketitle

% \section*{Acknowledgements}
% Acknowledgements go here. 

\tableofcontents
\listoffigures
\listoftables

%\pagenumbering{arabic}  <-- was commented out in the skeleton too


\chapter{Introduction}

[\textit{I plan to write this towards the end.}]

\chapter{Context and background}
\label{chap:background}

\section{Background work}
Researchers have been interested in computationally analysing narrative fiction for decades. However, this interest has dramatically increased along with the size of raw data available and the ability to store and process ever-growing data sets. In order to establish the basis of the work described in this report, we will highlight some of the previous literature which takes a character-centric point of view when approaching narrative fiction.

\subsection{The Persona Model}
\label{sec:bg_persona}
Recent work by David Bamman and others has explored the idea of learning the type or \textit{persona} of film \cite{Bamman2013} and literary \cite{Bamman2014} characters. A character persona is a probabilistic model of a character's personality traits, constructed using certain keywords from a film's plot summary. The papers present a number of variations of this model, but we will only describe the \textit{Dirichlet Persona Model} introduced in \cite{Bamman2013}, which serves as the basis for this work.

Instead of trying to build these models of character personality using information conveyed in the films themselves, such as dialogue or descriptions from the screenplays, Bamman and his colleagues relied on summaries of films' storyline, written by human editors on Wikipedia. These are usually concise, straightforward descriptions of the events and characters of a film, written in a neutral style. A more detailed discussion of the this data follows in Section~\ref{sec:data sets}. 

A core assumption in their model is that character personalities are primarily represented by three types of words in the plot summaries:
\begin{itemize}
	\item \textbf{Agent verbs:} Verbs for which the character is an agent (e.g. "Starling \textit{travels} to the victim's hometown")
	\item \textbf{Patient verbs:} Verbs for which the character is the patient or object (e.g. "Starling is \textit{led} to the house of Jack Gordon", where \textit{Starling} is a passive nominal subject)
	\item \textbf{Modifiers:} Other words which describe the characters (e.g. "Catherine is still \textit{alive}")
\end{itemize}
The classification of tokens into one of these categories is based on their Stanford Typed Dependencies \cite{de2008stanford}, assigned using the Stanford CoreNLP natural language analysis toolkit \footnote{http://nlp.stanford.edu/software/corenlp.shtml}.

In their \textit{Dirichlet Persona Model}, these words, along with their classification into the 3 categories described above are the only data used to infer the persona of a character. Aside from this model, they also explore an augmented one (\textit{Persona Regression}), which also takes some metadata into account, namely the age and gender of the characters (based on the gender and date of birth of the actor portraying that character) and the genre of the film.

\begin{figure}[ht!]
\centering
\begin{tikzpicture}

  % Define nodes
  \node[obs]                      (w) {$w$};
  \node[latent, above=of w]       (z) {$z$};
  \node[obs, right=of z]          (r) {$r$}; 
  \node[latent, above=of z]       (p) {$p$};
  \node[dash, above=of p]         (theta) {$\theta^{(d)}$};
  \node[latent, left=of theta]    (alpha) {$\alpha$};
  \node[dash, left=of w]          (phi) {$\phi^{(z)}$};
  \node[latent, below=of phi]     (gamma) {$\gamma$};
  \node[dash, left=of z]          (psi) {$\psi^{(r)}$};
  \node[latent, above=of psi]     (nu) {$\nu$};

  \edge {z}{w}
  \edge {r}{z}
  \edge {theta}{p}
  \edge {p}{z}
  \edge {alpha}{theta}
  \edge {phi}{w}
  \edge {gamma}{phi}
  \edge {psi}{z}
  \edge {nu}{psi}

  \plate {zwr} {(z)(w)(r)} {$W$};
  \plate {zwrp} {(zwr)(p)} {$E$};
  \plate {zwrp_theta} {(zwrp)(theta)} {$D$};

\end{tikzpicture}
\caption{Graphical model of the \textit{Dirichlet Persona Model} presented in \cite{Bamman2013}. Figure adapted from the one in the paper. As can be seen when comparing with Figure~\ref{fig:lda} below, it extends the LDA model.}
\end{figure}

In the model shown above, the words $w$ and their role $r$ (agent, patient, modifier) are the observed variables. $W$ is the total number of words. Each word is assigned a topic $z$. Topics $\phi$ are multinomial distributions over words in the vocabulary, with a Dirichlet prior, parameterised by $\gamma$. A persona $p$ is then defined as a set of 3 multinomial distributions $\psi$ over the topics, also with a Dirichlet prior, each parameterised by a $\nu_r$. At the document (film) level, characters' personas are also drawn from a multinomial distribution $\theta$, with a Dirichlet prior, parameterised by $\alpha$. The authors use collapsed Gibbs sampling \cite{griffiths2004finding} to sample the latent topic $z$ of each word and the persona $p$ of each character. 

For this project, a simpler model was used, described in Section~\ref{sec:persona_impl}, based directly on an implementation of Latent Dirichlet Allocation.

\subsection{Social networks in narrative fiction}
Another strand of work in this field is concerned with the interactions between characters and how that contributes to defining the story, rather than with their individual personalities. When analysing narratives and the characters that make up the story, we can think of representations that would capture their interactions and they ways in which they affect the story progression. An intuitive representation is that of a social network: a graph in which nodes are used to denote characters and edges represent some kind of interaction between them. Different variations of this model have been proposed.

Extracting and analysing social networks of characters from works of fiction has already proven valuable for a number of applications. In the context of novels, such an approach can be used to answer literary theory questions by taking into account a large sample of writings, rather then the small subset of well-known works which are usually examined by literary scholars. In their paper \cite{Elson2010}, Elson et al. propose a way in which social networks can be extracted from English novels and set out to answer disputed questions about the correlation between different features of narratives (e.g. first- or third-person perspective, urban or rural setting) and character interactions (e.g. cohesion of the social network). Their approach uses the number and length of quoted speech acts which are inferred to be directed from one character to another to assign a weight to the relationship between the characters.

Others have tried to extend the social network representation beyond quoted speech \cite{Agarwal2013}, also in the context of literary fiction. Using a wider concept of \textit{social events} \cite{agarwal2010annotation}, meant to include any ``deliberate" interaction not captured by direct speech (e.g., using the notation from the paper for characters and social events, ``\{He\} [was looking] at \{Tomas\} and [trying to smile]."\footnote{Kundera, Milan. \textit{The Unbearable Lightness of Being}. Translated by Richmond Hoxie. London: Faber \& Faber, 1984.}), Agarwal et al. proposed a method for automatically extracting social networks from texts and evaluated their result  by comparing their extracted social network from ``The Adventures of Alice in Wonderland" with a gold-standard annotated network, using standard network measures such as degree centrality, betweenness centrality and graph density.

Social network extraction has been attempted in many other contexts, including e-mail conversations, online communities... [TODO]. 

\subsection{Character-to-Character Sentiment Analysis}

[\textit{I have sketched the main ideas for this section, will need to develop it fully.}]

First work in sentiment analysis on works of fiction \cite{alm2005emotions}, on children's fairy tales.

Alm et al. also explore the role of ``emotion trajectories" in story development. \cite{alm2005emotional}.

Building on this previous work and on that of Elson et al., Elsner uses sentiment trajectories of individual characters rather than entire narratives \cite{elsner2012character}.

All these previous works focus on literary fiction rather than films.

Sentiment analysis and social networks. (Philip Gorinski used it in summarisation)

The main basis for the sentiment work in this project: \cite{Nalisnick2013} sentiment trajectories of individual characters based on speech acts in plays, adapted for films.



\section{Data sets} \label{sec:data sets}
We have mainly used two data sets to support the work done for this project. They have both been compiled as part of previous research efforts focused on computationally analysing films.

\subsection{The CMU Movie Summary Corpus}
A collection of 42,306 Wikipedia plot summaries of films, along with metadata extracted from Freebase. The summaries are processed using the \textit{Stanford CoreNLP} tools, specifically tagging, parsing, named entity recognition and coreference resolution.

\subsection{ScriptBase}
ScriptBase \cite{Gorinski2015} is a corpus of 1,276 film scripts, along with IMDB and Wikipedia metadata. Of these, 127 have been similarly processed using the \textit{Stanford CoreNLP} pipeline and standardized as XML files following a set schema.

[TO DO: \textit{More details on what kind of data is extracted in these corpora and specific pre-processing steps}]

[Wiki on plot summaries: "The plot summary is an overview of the film's main events, so avoid minutiae like dialogue, scene-by-scene breakdowns, individual jokes, and technical detail."]

\chapter{Aims and hypotheses}

The aims of this project were to explore different representation of films and identify what kinds of features can be captured by these representations. A big part of the work done as part of the project was directed at probing these possibilities, by constructing variations of the character graph representation and measuring their effectiveness using a number of prediction tasks. Inevitably, not all of them produced significant results or were even practical to test. Along with our main hypothesis, we will present some of the work which did not yield any fruit and discuss the underlying reasons.

\section{Inter-character sentiment}
In one sentence, the main hypothesis is that character graph representations can be used to predict inter-character sentiment. As discussed in Chapter~\ref{chap:background}, there have been previous attempts to link character social networks and some form of sentiment analysis. By using character personas and a measure of the strength of two characters' relationships to predict aspects of the sentiment in speech acts directed from one character to the other, we can bring together two distinct aspects of film narratives and show that they correlate. On the level of the text resources used, we link the raw dialogue of a film (from the film scripts) and the human-produced plot summaries. On the narrative level, we correlate the \textit{actions} of characters (as described in the plot summaries) with their utterances. [\textit{Note: I think this is really interesting, but I'm not sure how to develop it.}]

\section{Alternative hypotheses}

\subsection{TV Tropes}
TV Tropes\footnote{http://tvtropes.org/} is an online public wiki maintaining a collection of ``tropes", such as plot devices, dialogue commonalities, motifs and other conventions or stereotypes that are widely used in film and television series. More recently it ha also grown to include literature, video games and other media. Apart from collecting the tropes themselves, TV Tropes maintains pages for numerous individual films and other works of fiction which include a list of the tropes that they feature.

TV Tropes have been used in past research efforts, most notably by Bamman et al. \cite{Bamman2013}, as part of one of the evaluation measures for their film persona models introduced in Section~\ref{sec:bg_persona}. They selected 72 tropes which correspond to character types (e.g. \textit{The Hardboiled Detective}) and manually annotated 501 characters. They attempted to recover gold-standard clusters of characters as determined by their trope assignment and used an information-theoretic measure to assess the discrepancy between these and the latent persona clusters.

We considered the possibility of evaluating our character graph representations on the basis of being able to capture different kinds of relationships between 2 or more characters (e.g. one of the \textit{Triang Relations}\footnote{http://tvtropes.org/pmwiki/pmwiki.php/Main/TriangRelations} or \textit{Four-Man Band}. For this purpose, we have implemented a scraper in order to collect the tropes associated with the films in our data set. Table~\ref{table:tropes} shows the most common 20 tropes and the number of films which feature them.

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\begin{table}[h!]
\centering
\begin{tabular}{|c||L{4.5cm}|l|c|c||L{4.5cm}|l|}
\cline{1-3} \cline{5-7}
1 & Shout-Out & 54 & & 11 & Berserk Button & 22 \\ \cline{1-3} \cline{5-7}
2 & Deadpan Snarker & 31 & & 12 & Cluster F-Bomb & 19 \\ \cline{1-3} \cline{5-7}
3 & Lampshade Hanging & 27 & & 13 & Butt Monkey & 18 \\ \cline{1-3} \cline{5-7}
4 & Chekhov's Gun & 27 & & 14 & Large Ham & 18 \\ \cline{1-3} \cline{5-7}
5 & Running Gag & 26 & & 15 & Badass & 18 \\ \cline{1-3} \cline{5-7}
6 & Oh, Crap & 25 & & 16 & Ax-Crazy & 18 \\ \cline{1-3} \cline{5-7}
7 & Brick Joke & 24 & & 17 & Title Drop & 17 \\ \cline{1-3} \cline{5-7}
8 & Precision F-Strike & 23 & & 18 & Word Of God & 17 \\ \cline{1-3} \cline{5-7}
9 & Foreshadowing & 23 & & 19 & Meaningful Name & 16 \\ \cline{1-3} \cline{5-7}
10 & Black Comedy & 22 & & 20 & Even Evil Has Standards & 16 \\ \cline{1-3} \cline{5-7}
\end{tabular}
\caption{The 20 most frequent TV Tropes and the number of films which feature them (out of the 83 films in the collection)}
\label{table:tropes}
\end{table}

None of these 20 tropes describe character relationships in any way. Most of them capture plot devices, features of speech or stylistic choices. Lacking a significant number of films (all other tropes are featured in less than 16 films) which include any kind of stereotypical and easily identifiable character relationships, we were not able to use TV Tropes to evaluate the character graph representation.

\subsection{Film similarity}

\chapter{Design and Implementation}

This chapter details the components of the software pipeline implemented as part of the project to acquire and process data, construct character graphs and carry out experiments. The system was primarily programmed using Python 2.7.6. The language was chosen for the terse and flexible style of programming that it enables and for its adoption in the NLP community, having a large ecosystem of libraries and tools developed around it. Some parts concerned with parsing script files and gathering film similarity judgements from Rotten Tomatoes were implemented using F\# 3.1. This choice was made on the basis of F\#'s smooth integration with external data sources and ease of working with schematised data.

The structure of the Python project is shown in Figure~\ref{fig:dirtree}. Directories and source files in the root directory correspond to the major areas of implementation, which can roughly be categorised as follows (by directory/file):
\begin{itemize}
	\item \texttt{\textbf{topics}}:  Extract and filter plot summary data, run Latent Dirichlet Allocation and pickle the resulting topic distributions
	\item \texttt{personas.py}: Define a \texttt{Persona} class, compute the persona for each character and pickle them
	\item \texttt{graphs.py}: Construct character graphs and implement various functions for working with them (e.g. filter nodes/edges)
	\item \texttt{film.py}: Define a \texttt{Film} class, which stores the character graphs and matches them with various pieces of metadata (e.g. title, year, names of characters)
	\item \texttt{\textbf{sentiment}}: Extract speech acts from processing film scripts and construct sentiment trajectories between pairs of characters
	\item \texttt{\textbf{prediction}}: Implements various predictors and tools for feature engineering and running repeated experiments with different configurations
	\item \texttt{\textbf{utils}}: Processing raw data, pickling and other utility functions required throughout the project
\end{itemize}

The names of the rest of the source files give a good indication of what functionality they implement and should serve as a guide for exploring the source code.

\hspace{.1in}
\begin{figure}[ht!]
\dirtree{%
.1 \textbf{python}.
.2 \textbf{topics}.
.3 acquire\_vocab.py.
.3 filter\_genres.py.
.3 model\_topics.py.
.2 \textbf{sentiment}.
.3 trajectories.py.
.2 \textbf{prediction}.
.3 decision\_tree.py.
.3 random\_forest.py.
.3 svm.py.
.3 lin\_regression.py.
.3 ridge\_regression.py.
.3 regression\_tree.py.
.3 svm\_regression.py.
.3 features.py.
.3 predict.py.
.2 \textbf{utils}.
.3 filter\_summaries.py.
.3 process\_summaries.py.
.3 process\_scripts.py.
.3 store\_sentiment.py.
.3 misc.py.
.2 films.py.
.2 personas.py.
.2 graphs.py.
.2 compare.py.
.2 run\_topic\_model.py.
}
\caption{General structure of the Python code written for the project}
\label{fig:dirtree}
\end{figure}

The code for constructing the Rotten Tomatoes film similarity graph was written in F\#. Its structure is outlined in Figure~\ref{fig:fsharpdirtree}.

\begin{figure}[th!]
\dirtree{%
.1 \textbf{\texttt{rtgraph}}.
.2 Graph.fs.
.2 ApiCalls.fs.
.2 ToGEXF.fs.
.2 Main.fs.
}
\caption{General structure of the F\# code written for the project}
\label{fig:fsharpdirtree}
\end{figure}

\section{The Character Graph}
In order to construct the character graph for a film we need to find a meaningful representation of the relationship between characters (the nodes in our graph). For simplicity, we can start by trying to find a numerical measure, which would correspond to edge weights in an undirected weighted graph. The measure we have used in this project is the number of scene co-occurrences between two characters. Thus, the weight of an edge between two characters represents the number of scenes in which those characters appear together. As a consequence, characters which never interact in the film will be disconnected in the graph. When comparing the character graphs of different films, these weights will be normalised (by the total number of scenes in the film).

Apart from simplicity, choosing this measure can enable us to reliably discover the main characters of a film using a graph centrality indicator. However, scene co-occurrence does not give any insights into the \textit{nature} of the interaction between characters.

\subsection{Processing ScriptBase screenplays}
To ease the task of extracting the number of character to character scene co-occurrences, we restricted the set of films to the 127 which have already been processed in ScriptBase. A processed script is an XML file which, apart from the standard CoreNLP annotations, also places every sentence inside a numbered \texttt{scene} tag. It also distinguishes between stage directions and speech, annotating the name of the speaker(s) in the latter case.

Thus, it is straightforward to parse the XML document and, for each pair of characters, record the number of scenes in which they both have at least one line of speech. Note that although this approach ignores characters which might be present in a scene but do not speak, in practice we do not expect this to influence the results significantly.

\subsection{Constructing character graphs}
For representing character graphs, we have chosen GEXF\footnote{The GEXF file format, \textit{http://gexf.net}}, a standard XML format for describing general network structures. As described above, we simply extract all the character names from the script and use them as the set of nodes in the graph. We add a weighted edge for all the recorded interactions between characters. As a result, every film (of the 127 which we considered) will be represented with a GEXF file.

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{figures/clarice_graph}
	\caption{Character graph of \textit{The Silence of the Lambs} (1991), centred around the protagonist, Clarice Starling. Red vertices are those adjacent to Starling. Edge size is proportional to the number of scene co-occurrences between two characters.}
\end{figure}

\section{The Persona Model}
\label{sec:persona_impl}
We implemented a variation of the Dirichlet Persona Model introduced in \cite{Bamman2013} and briefly described above.

\subsection{Processing the CMU script summaries}
The CMU corpus provides both the raw plot summaries and a file containing all the processed summaries, which can be used as input for the pipeline described in their paper. We have designed ours to work with the same input format, enabling us to use the data from this corpus without any additional preprocessing, apart from filtering out the films for which we have not constructed a character graph. This includes the majority of films in the corpus. Out of the 127 films from ScriptBase, 96 also have a processed plot summary.

The filtered film data file contains, for each film and each character mentioned in the plot summary, a list of words tagged as being either \textit{agent}, \textit{patient} or \textit{modifier} words (as detailed in Section~\ref{sec:bg_persona}). These words are selected into one of these types on the basis of their Stanford typed dependencies, as determined using the CoreNLP parser. Each of the three types described above corresponds to a list of dependencies and all tokens tagged with those dependencies will be assigned a type. In the final input file, in addition to the word lemma, its type (agent, patient, modifier) and its dependency tag, the word tuples for each character also contain the part of speech and the WordNet supersense.


\subsection{Constructing the persona model}
In this project we implement a simpler version of the Dirichlet persona model \cite{Blei2003}. The original model was implemented as generative model. In the paper, a persona is defined as a set of 3 distributions (corresponding to agent, patient and modifier words) over topics, which are in turn distributions over words, similar to topic in Latent Dirichlet Allocation.

\begin{figure}[h!]
\centering
\begin{tikzpicture}

  \node[obs]                               (w) {$w$};
  \node[latent, above=of w]                (z) {$z$};
  \node[dash, above=of z]              (theta) {$\theta^{(d)}$};
  \node[latent, left=of theta]        (alpha) {$\alpha$};
  \node[dash, left=of w]                 (phi) {$\phi^{(z)}$};
  \node[latent, below=of phi]          (gamma) {$\gamma$};

  \edge {z}{w}
  \edge {theta}{z}
  \edge {alpha}{theta}
  \edge {phi}{w}
  \edge {gamma}{phi}

  \plate {zw} {(z)(w)} {$W$};
  \plate {zwt} {(zw)(theta)} {$D$};

\end{tikzpicture}
\caption{Graphical model for Latent Dirichlet Allocation (LDA)}
\label{fig:lda}
\end{figure}


We have opted to use the standard LDA algorithm, as implemented in the Python \texttt{lda 0.3.2} package \footnote{ www.pypi.python.org/pypi/lda} in order to derive the latent topics in our vocabulary and use a simple maximum likelihood estimation method to compute each character's 3 distributions over these latent topics.

One of the advantages of this frequentist approach is that the only parameter that we need to optimise in the model is the number of topics computed by the LDA algorithm. Since the number of films in our collection is small and largely restricted to two genres (thriller and comedy), we expect the number of meaningful topics to also be reasonably small. Therefore we have tried to manually vary this parameter and select the value which seems to intuitively give a complete coverage of topics, without having different topics which seem very close. We have used to highest probability words in each topic distribution as a guide. So far, we have settled on having 10 topics (\textit{Figure 1.2}).

\begin{figure}[h]
\centering
\begin{minipage}{8cm}
\begin{Verbatim}[frame=single]
0: tell take go have 
1: stop arrive hide officer 
2: mother decide love marry 
3: meet discover leave confront 
4: join wife know lie 
5: girl son offer husband 
6: give kill confront offer
7: kill shoot brother find 
8: pursue criminal escape ndapp
9: set capture try save 
\end{Verbatim}
\end{minipage}
\caption{First 4 words in the 10 topics discovered by LDA on our film collection, ranked by probability. TO DO: \textit{Need to update these}}
\label{topics}
\end{figure}

Having these 10 distributions over words in the vocabulary, we construct, for each character, a set of 3 distributions over these topics, by multiplying the number of different occurrences of a certain word lemma with the probability of that lemma in a certain topic, then normalising. It is then easy to compare the persona of two different characters, by using any distance measure, such as Euclidean distance.


\section{Sentiment trajectories}

TODO

\begin{figure}[h!]
	\includegraphics[scale=0.335]{figures/sentiment}
	\caption{Sentiment trajectories between the two most central characters in \textit{The Silence of the Lambs} (1994) and \textit{Midnight in Paris} (2011) [TO DO: \textit{Label axes}]}
\end{figure}

\section{Testing the main hypothesis}
\label{sec:predictors}
In order to test the main hypothesis, a number of prediction tasks were considered, including both classification and regression problems. The tasks themselves and the results are detailed more fully in Chapter~\ref{chap:results}. Here, we will outline the main machine learning techniques used, the reasons for choosing them and their implementation. The toolkit used for carrying out machine learning tasks was the \textit{scikit-learn}\footnote{http://scikit-learn.org/stable/} Python library. It was used for the implementation of the predictors described below, for evaluating the trained models using cross-validation and for generating confusion matrices.

\subsection{Classification}
[TODO: Define each of these predictors]
\begin{itemize}
	\item \textbf{Decision trees:} Used the \texttt{DecisionTreeClassifier} class implemented in \textit{scikit-learn}.
	\item \textbf{Random forests}
	\item \textbf{Support vector machines}
\end{itemize}


\subsection{Regression}
[TODO: Define each of these predictors]
\begin{itemize}
	\item \textbf{Linear regression}
	\item \textbf{Ridge regression}
	\item \textbf{Decision tree regression}
	\item \textbf{SVM regression}
\end{itemize}

\section{Testing alternative hypotheses}

\subsection{Predicting TV Tropes}
\subsubsection{Scraping the TV Tropes website}
[TO DO: \textit{Outline implementation of scraper}]

\subsection{Comparing character graphs}
Once the character graphs are constructed, the nodes can be annotated with the persona information. Note that although the character graphs are likely to contain a node for every character in the plot (a small variation can occur due to faults in the preprocessing of scripts), personas will be computed for 2-5 main characters. Again, due to the limitations of the standard NLP tools (most notably coreference resolution), this number can be lower, sometimes even 0.

To represent annotated graphs in our project, we have used the Python \texttt{networkx} library \footnote{www.networkx.github.io}.

\subsubsection{Direct matching based on centrality}
The simplest comparison measure implemented is based on matching characters from different graphs based on their role in the network. Using degree centrality, the nodes of each graph are sorted and only the first 10 nodes are kept. This is a parameter that can be experimentally adjusted, but we have set it to 10 initially because for every film in the collection, we could not compute a persona for any character that has rank below 10 by degree centrality.

[TO DO: \textit{Detail why character matching is complicated}]

Then, every pair of corresponding characters (by rank) in the two graphs is compared. Note that although a persona is a set of 3 distributions, not all characters will have a distribution defined for all 3 types (agent, patient, modifier), since the relevant word lemmas might not be present in the plot summary. Therefore, we compare the distributions which both characters have in common, by taking the norm of the difference between the 2 vectors. The film similarity score is computed as the average of these differences: the lower the score, the more similar the graphs are deemed to be.

\begin{figure}[h]
\centering
\begin{minipage}{11.5cm}
\begin{Verbatim}[frame=single]
Star Trek V    - The Anniversary Party     (0.00167)
Ghost World    - I Love You Phillip Morris (0.00193)
Ghost World    - Copycat                   (0.00202)
Ghost World    - Clerks                    (0.00236)
Ghost World    - Miller's Crossing         (0.00257)
Ghost World    - Nick of Time              (0.00275)
Ghost World    - Sweeney Todd              (0.00338)
The Informant! - The Hangover              (0.00351)
Ghost World    - Gothika                   (0.00352)
Jaws           - Living in Oblivion        (0.00410)
\end{Verbatim}
\end{minipage}
\caption{The 10 most similar pair of films in our collection of 96 thrillers and comedies, based on comparing personas matched by degree centrality rank}
\end{figure}

In these results, it is easy to see that the comedy \textit{Ghost World} dominates the similarity pairings, being matched both with comedies and thrillers. Overall, the results do not seem to be very revealing. To understand why this might be the case, let us explore the example of \textit{Ghost World}, by showing the top 10 characters and the top 3 topics for each character that has a persona defined. Each topic is described by the top 3 most probable words in that topic.

\begin{figure}[h]
\centering
\begin{minipage}{9cm}
\begin{Verbatim}[frame=single]
ENID 
REBECCA [ M(join wife know)
          M(pursue criminal escape)
          M(girl son offer) ]
SEYMOUR [ P(tell take go)
          A(tell take go)
          A(meet discover leave) ]
ROBERTA [ A(give kill confront)
          A(girl son offer)
          M(girl son offer) ]
JOE 
CUSTOMER 
PAUL 
GERROLD 
JEROME 
STEVEN 
\end{Verbatim}

\end{minipage}
\caption{The 10 most central characters in \textit{Ghost World} and their personas}
\end{figure}

One explanation for the dominance of \textit{Ghost World} in the similarity results shown above is the fact that its characters seem to be typical of both romantic comedies (topics such as \texttt{(join wife know)} or \texttt{(meet discover leave)}) and thrillers (topics like \texttt{(give kill confront)}).

We suspect that one of the causes of the weak results is the small number of films in our collection and, consequently, the small number of words in the vocabulary. This can lead to a topic clustering which does not have much discriminative power (see the list of topics in Figure \ref{topics}). It might also be the case that, since not many personas are matched between films, these occasional matches might be insufficient for obtaining meaningful results across the whole corpus.

\subsection{Rotten Tomatoes similarity}
One of the aims of the project was to determine whether character graphs can be useful in predicting film similarity, based on human judgements. In order to test this hypothesis, independent from the work described so far, we have also tried to construct a gold-standard collection of film similarity pairs, using data supplied by Rotten Tomatoes\footnote{www.rottentomatoes.com}. Their public API supports requests of the form "What films have users deemed to be similar to this one?" and offers up to 5 results.

We have found that the results obtained by querying every film in the collection and discarding every returned film which is not part of the collection yields a very small number of pairs. Thus, we have expanded the similarity measure by constructing a graph in which films are nodes and edges represent similarity and allowing films from outside the corpus. The similarity can then be measured as the minimum distance in the graph.

However, the limited number of films in our collection and the fact that they are quite diverse (i.e. it is difficult to find pairs for which human judgements indicate similarity) meant that we could not meaningfully assess whether character graphs can be used to predict general film similarity. 

\chapter{Results and discussion}
\label{chap:results}

From its onset, this project was exploratory in nature. Experimenting with various film representations and the kinds of features that they can reliably predict was one of the main goals. The results presented in this chapter and the subsequent discussion will offer some insight into what can be achieved when using the character graph representation of films proposed above. Specifically, we will look at different ways in which persona information and character relationships can be combined and correlated. We ran a large number of experiments, exploring different transformations of the feature space and various machine learning techniques. This chapter will provide an overview of the types of prediction problems attempted and report interesting experimental results.

\section{Experimental setup and data transformations}
The same experimental setup and basic data is used for all of the prediction tasks detailed below. The starting point is the set of 876 character-to-character relationships, described by the persona of each character and the weight of the edge between them in the character graph. Since out topic model has 10 topics and each persona is a set of 3 distributions over the latent topics, each feature vector will have size 61 ($2 \cdot 30$ persona variables $+ 1$ edge weight). Each feature vector will have an associated label, depending on the prediction task, which will characterise some aspect of the sentiment between the two characters. The character relationships are directed, since we are attempting to capture the sentiment expressed by one character towards another. As a result, each pair of interacting characters will be represented by 2 feature vectors in the data set, with their persona distributions swapped.

\subsection{Data transformations}
Apart from using the the whole data set described above, we have also tried to explore ways in which the feature vectors can be transformed in order to yield the most significant results. To this effect, we have designed and implemented the experimental setup in order to be able to answer questions such as:
\begin{enumerate}
	\item Are all 3 distributions on the persona model (\textit{agent}, \textit{patient}, \textit{modifier}) equally relevant?
	\item Can we get better predictions is we only use characters that have a more central role in the story?
	\item Should we use a uniform distributions for characters without persona information or should we exclude them altogether?
	\item Is it just a small number of topics that mostly define the persona of a character or are all 10 topics useful?
\end{enumerate}
And, naturally,
\begin{enumerate}
	\setcounter{enumi}{4}
	\item Does using the edge weight as a feature result in better predictions over simply using the persona model and vice-versa?
\end{enumerate}

When running experiments, the user can choose to either explore a certain data space (e.g. \textit{Make predictions using every combination of two persona distributions, rather than using all 3 of them.}, which will result in 3 possible configurations), or tu run on a predefined set of configurations. The next subsection explains what parameters can be specified when doing so\footnote{The code which facilitates this is found in the \texttt{main} method of \texttt{python/predictions/predict.py}}. 

\subsubsection{Presentation of results}
As a consequence, when presenting prediction results in the remainder of this chapter, they will be accompanied by the context in which they were obtained. The purpose of this section is to explain what the columns under \textit{Configuration} in the results tables mean:
\begin{itemize}
	\item \textit{Number of nodes:} The (maximum\footnote{The number could be less than the one shown in a configuration where nodes without a persona are filtered out}) number of characters from each film that were used. These were selected based on their centrality in the character graph. Its value can either be \textit{All} or a number from 1 to 10.
	\item \textit{Filter personas:} \textit{Yes} or \textit{No} value, depending on whether nodes without persona information were filtered out, or their personas were filled in with uniform distributions.
	\item \textit{Personas used:} Shows which of the 3 distributions in a character persona were used. Can be any non-empty subset of $\{A, P, M\}$ (standing for \textit{agent}, \textit{patient} or \textit{modifier}).
	\item \textit{Top topics only:} Its value can be either \textit{All topics}, showing that the persona distributions were used unmodified, or a number $n$ between 1 and 9, meaning that, for each distribution, the top $n$ topics by probability were chosen, the rest were made 0 and the distribution was then normalised.
	\item \textit{Edge used:} \textit{Yes} or \textit{No} value, showing whether the edge weight between two characters was added as a feature or not.
\end{itemize}

\section{Predicting inter-character sentiment}

\subsection{Predicting sentiment polarity}
[TODO: revise this paragraph] The compound sentiment prediction task by regression is quite an ambitious goal, especially with the limited dataset that is being used. In this section, we consider a more constrained version of this problem: predicting compound sentiment polarity, modelled as a 2-class classification task. As discussed in Section~\ref{sec:predictors}, the classifiers used are decision trees, random forests and SVMs. In the case of random forest, 20 classifiers were trained on each configuration and the best one was selected.

Note that for classification tasks, the baseline we are comparing to is the proportion of positive relationships in the total number of character relationships. As can be seen in the results tables below, they usually significantly outnumber the negative sentiment relationships, making them the simplest realistic baseline to compare our predictors against. In this case, the simplest possible classifier would simply predict all relationships as having positive sentiment. Models performing better than this baseline are highlighted in the tables.

We will first try to use the entire data set of 876 character relationships, with all 3 persona distributions across all topics (Table~\ref{res:full_set}). Decision trees, do not manage to out-perform the baseline, while random forests and SVMs are narrowly more accurate than it, but the difference is never more than 4\%. When using the data set in which characters with missing personas are not filtered out, but their personas are treated as uniform distributions over the latent topics, no predictor manages to beat the deadline by more than 1\%. One aspect to note is that for both random forests and SVMs, using the edge weight either improved or had no effect on the accuracy.

\begin{table}[h!]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{ |c|c|c|c|c|c!{\vrule width 1.5pt}c|c| }
\cline{1-6}
\multicolumn{6}{ |c!{\vrule width 1.5pt} }{Configuration}\\
\hline
 & No. & Filter & Personas & Top topics & Edge & & \\
Classifier & nodes & personas & used & only & used & Baseline & \textbf{Accuracy} \\ \hline
\multirow{4}{*}{Decision tree} 
 & All & Yes & A, P, M & All topics & Yes & 0.733 & 0.648\\
 & All & Yes & A, P, M & All topics & No & 0.733 & 0.670\\ 
 & All & No & A, P, M & All topics & Yes & 0.871 & 0.872\\
 & All & No & A, P, M & All topics & No & 0.871 & 0.871\\ \hline
\multirow{4}{*}{Random forests} 
 & All & Yes & A, P, M & All topics & Yes & 0.733 & \textbf{0.773}\\
 & All & Yes & A, P, M & All topics & No & 0.733 & \textbf{0.767}\\ 
 & All & No & A, P, M & All topics & Yes & 0.871 & \textbf{0.878}\\
 & All & No & A, P, M & All topics & No & 0.871 & \textbf{0.877}\\ \hline
\multirow{4}{*}{SVMs} 
 & All & Yes & A, P, M & All topics & Yes & 0.733 & \textbf{0.761}\\
 & All & Yes & A, P, M & All topics & No & 0.733 & \textbf{0.761}\\ 
 & All & No & A, P, M & All topics & Yes & 0.871 & \textbf{0.879}\\
 & All & No & A, P, M & All topics & No & 0.871 & \textbf{0.879}\\ \hline
\end{tabular}
\caption{Sentiment polarity predictions obtained by using the entire dataset and the full persona representation.}
\label{res:full_set}
\end{adjustwidth}
\end{table}

We will now try to train the same classifiers with different configurations. First, we will remove the restriction that all characters in a film need to be used. We expect this to increase accuracy because some of the minor characters have less accurate persona information since they are less likely to be mentioned in a plot summary. Furthermore, their sentiment trajectories will have significantly fewer events, limited by the number of on-screen interactions that they are involved in. We will explore the range between 2 and 5 as the maximum number of characters from each film. The nodes are selected according to their rank in the character graph, which is the reverse order of degree centrality.

Table~\ref{res:diff_nodes} show that the best results were obtained when limiting the number of characters to either 2 or 3. The results for all 3 classifiers are significantly better than those obtained when just using all characters.

\begin{table}[ht!]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{ |c|c|c|c|c|c!{\vrule width 1.5pt}c|c| }
\cline{1-6}
\multicolumn{6}{ |c!{\vrule width 1.5pt} }{Configuration}\\
\hline
 & No. & Filter & Personas & Top topics & Edge & & \\
Classifier & nodes & personas & used & only & used & Baseline & \textbf{Accuracy} \\ \hline
\multirow{2}{*}{Decision tree} 
 & 2 & Yes & A, P, M & All topics & Yes & 0.713 & \textbf{0.750}\\
 & 2 & Yes & A, P, M & All topics & No & 0.713 & \textbf{0.750}\\ \hline
\multirow{2}{*}{Random forest} 
 & 2 & Yes & A, P, M & All topics & Yes & 0.713 & \textbf{0.875}\\
 & 3 & Yes & A, P, M & All topics & No & 0.699 & \textbf{0.882}\\ \hline
\multirow{2}{*}{SVM}
 & 3 & Yes & A, P, M & All topics & Yes & 0.699 & \textbf{0.824}\\ 
 & 3 & Yes & A, P, M & All topics & No & 0.699 & \textbf{0.824}\\ \hline
\end{tabular}
\caption{Best sentiment polarity prediction accuracy obtained when varying the maximum number of characters for each film.}
\label{res:diff_nodes}
\end{adjustwidth}
\end{table}

Next, we will both vary the maximum number of characters in the film (this time limiting the search space to just 2 or 3 nodes), as before, and let the persona include any subset of the 3 distributions. Results are shown in Table~\ref{res:diff_nodes_personas}. Note that for random forests, a third row of results is included in order to compare the accuracy of either using or not using edge weights on the same configuration that yielded the best performance in the first case.

\begin{table}[ht!]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{|c|c|c|c|c|c!{\vrule width 1.5pt}c|c| }
\cline{1-6}
\multicolumn{6}{ |c!{\vrule width 1.5pt} }{Configuration}\\
\hline
 & No. & Filter & Personas & Top topics & Edge & & \\
Classifier & nodes & personas & used & only & used & Baseline & \textbf{Accuracy} \\ \hline
\multirow{2}{*}{Decision tree} 
 & 2 & Yes & A, M & All topics & Yes & 0.713 & \textbf{0.750}\\
 & 3 & Yes & A, M & All topics & No & 0.699 & \textbf{0.706}\\ \hline
\multirow{3}{*}{Random forest} 
 & 2 & Yes & A & All topics & Yes & 0.713 & \textbf{0.938}\\
 & 2 & Yes & A, M & All topics & No & 0.713 & \textbf{0.938}\\ 
\rowcolor{gray!35}
{\cellcolor{white}} & 2 & Yes & A & All topics & No & 0.713 & \textbf{0.875} \\ \hline
\multirow{2}{*}{SVM}
 & 3 & Yes & A, P, M & All topics & Yes & 0.699 & \textbf{0.824}\\ 
 & 3 & Yes & A, P, M & All topics & No & 0.699 & \textbf{0.824}\\ \hline
\end{tabular}
\caption{Best sentiment polarity prediction accuracy obtained when varying the maximum number of characters for each film and allowing the persona to include any subset of the 3 distributions it contains.}
\label{res:diff_nodes_personas}
\end{adjustwidth}
\end{table}

Finally, we will now also allow the persona distributions to either include all topics, or to only select $n$ topics, set the probability of the others to 0 and normalise. Results are shown in Table~\ref{res:vary_everything}. Note that the highlighted row has been included in order to compare the accuracy of SVMs on the same number of maximum characters (same baseline) with the best model from the previous task. The percentages in brackets indicate the change in accuracy between this in the previous task, where best results are comparable (i.e. they have the same baseline).

The accuracy of these models is generally better than in the previous configurations. It remains unchanged in the case of random forests, for which allowing the number of latent topics to vary did not result in an increase in accuracy. These are the best results obtained in the sentiment polarity classification tasks. For all the trained classifiers, they are significantly higher than the baseline.

\begin{table}[ht!]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{ |c|c|c|c|c|c!{\vrule width 1.5pt}c|c| }
\cline{1-6}
\multicolumn{6}{ |c!{\vrule width 1.5pt} }{Configuration}\\
\hline
 & No. & Filter & Personas & Top topics & Edge & & \\
Classifier & nodes & personas & used & only & used & Baseline & \textbf{Accuracy} \\ \hline
\multirow{2}{*}{Decision tree} 
 & 2 & Yes & A & 6 & Yes & 0.713 & \textbf{0.813 (+6.3\%)}\\
 & 2 & Yes & A, M & 3 & No & 0.713 & \textbf{0.938}\\ \hline
\multirow{2}{*}{Random forest} 
 & 2 & Yes & A & All topics & Yes & 0.713 & \textbf{0.938} (+0.0\%)\\
 & 2 & Yes & A, M & All topics & No & 0.713 & \textbf{0.938} (+0.0\%)\\ \hline
\multirow{3}{*}{SVM}
 & 2 & Yes & A & 3 & Yes & 0.713 & \textbf{0.875}\\
 & 2 & Yes & A & 3 & No & 0.713 & \textbf{0.875}\\ 
\rowcolor{gray!35}
{\cellcolor{white}} & 3 & Yes & A & 1 & -- & 0.699 & \textbf{0.853 (+2.9\%)}\\ \hline
\end{tabular}
\caption{Best sentiment polarity prediction accuracy obtained when varying the maximum number of characters for each film, allowing the persona to include any subset of the 3 distributions it contains and varying the number of topics over which personas are distributed.}
\label{res:vary_everything}
\end{adjustwidth}
\end{table}

\subsection{Predicting changes in sentiment}
As can be seen in the graphs shown in Section~[TODO ref], it appears that the way inter-character sentiment evolves intuitively conveys certain aspects about the nature of the narrative and the characters which take part (e.g. in a romantic film, both of the main characters tend to express positive sentiment throughout). We will now consider another prediction problem: can we predict whether inter-character sentiment has a positive trend, a negative trend or does not vary over the course of the film?

[TODO details about constructing the classes]

\begin{table}[ht!]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{ |c|c|c|c|c|c!{\vrule width 1.5pt}c|c| }
\cline{1-6}
\multicolumn{6}{ |c!{\vrule width 1.5pt} }{Configuration}\\
\hline
 & No. & Filter & Personas & Top topics & Edge & & \\
Classifier & nodes & personas & used & only & used & Baseline & \textbf{Accuracy} \\ \hline
\multirow{2}{*}{Decision tree} 
 & All & Yes & A & 7 & Yes & 0.430 & \textbf{0.479}\\
 & All & Yes & A & 7 & No & 0.430 & \textbf{0.479}\\ \hline
\multirow{2}{*}{Random forest} 
 & All & Yes & A & 5 & Yes & 0.430 & \textbf{0.606}\\
 & All & Yes & A & 5 & No & 0.430 & \textbf{0.592}\\ \hline
\multirow{2}{*}{SVM}
 & All & Yes & A & 5 & Yes & 0.430 & \textbf{0.493}\\
 & All & Yes & A & 5 & No & 0.430 & \textbf{0.493}\\ \hline
\end{tabular}
\caption{Best sentiment variation prediction accuracy, with $\alpha = 1.0$.}
\label{res:sent_variation}
\end{adjustwidth}
\end{table}



\subsection{Predicting compound sentiment}
We have modelled previous tasks as classification problems. However, inter-character sentiment is a continuous numerical value, meaning we can also explore regression tasks. The broadest such task is simply predicting the value of inter-character compound sentiment. Attempting to obtain the best possible results, we will explore the whole space of configurations introduced in the sections above. Results are shown in Table~\ref{res:regression}. 

\begin{table}[ht!]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{ |c|c|c|c|c|c!{\vrule width 1.5pt}c| }
\cline{1-6}
\multicolumn{6}{ |c!{\vrule width 1.5pt} }{Configuration}\\
\hline
 & No. & Filter & Personas & Top topics & Edge & \textbf{Mean squared}\\
Classifier & nodes & personas & used & only & used & \textbf{error} \\ \hline
\multirow{2}{*}{Linear regression} 
 & All & Yes & M & 7 & Yes & 10.19\\
 & All & Yes & M & 7 & No & 10.19\\ \hline
\multirow{2}{*}{Ridge regression} 
 & All & Yes & A, M & 7 & Yes & 10.30\\
 & All & Yes & A, M & 7 & No & 10.28\\ \hline
\multirow{2}{*}{\parbox{2.3cm}{Decision tree regression}}
 & All & Yes & A & 2 & Yes & 10.55\\
 & All & Yes & A & 2 & No & 10.50\\ \hline
\multirow{2}{*}{SVM regression}
 & All & Yes & A & 3 & Yes & 10.99\\
 & All & Yes & A & 3 & No & 10.99\\ \hline
\end{tabular}
\caption{Best sentiment polarity prediction accuracy.}
\label{res:regression}
\end{adjustwidth}
\end{table}


\chapter{Future work}

\bibliographystyle{plain}
\bibliography{collection}

\end{document}
